{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainnet.config import get_cfg_defaults\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "\n",
    "# manually download and unzip subj01.zip from algonauts2023 challenge\n",
    "# https://docs.google.com/forms/d/e/1FAIpQLSehZkqZOUNk18uTjRTuLj7UYmRGz-OkdsU25AyO3Wm6iAb0VA/viewform\n",
    "cfg.DATASET.DATA_DIR = \"/home/admin/Algonaut/data/algonauts2023/subj02\"\n",
    "cfg.DATASET.BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for google colab\n",
    "#!pip3 install natten -f https://shi-labs.com/natten/wheels/cu117/torch2.0.0/index.html --quiet \n",
    "#!pip install openmim\n",
    "#!mim install mmdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "\n",
    "#del trainer\n",
    "#del plmodel\n",
    "#del backbone\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract backbone state from checkpoints\n",
    "\n",
    "def extract_backbone(ckpt):\n",
    "    state = {}\n",
    "    for k in ckpt.keys():\n",
    "        if 'backbone' in k:\n",
    "            new_k = k.split('backbone.')[1]\n",
    "            state[new_k] = ckpt[k]\n",
    "    return state\n",
    "\n",
    "ckpt_f = '/home/admin/Algonaut/dat_backbones/cmrcn_dat_b_3x.pth'\n",
    "ckpt = torch.load(ckpt_f)['state_dict']\n",
    "state = extract_backbone(ckpt)\n",
    "torch.save(state, '/home/admin/Algonaut/dat_backbones/bkbn_cmrcn_dat_b_3x.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dat_backbone.dat import DAT\n",
    "backbone = DAT()\n",
    "backbone.load_state_dict(torch.load('/home/admin/Algonaut/dat_backbones/bkbn_upn_dat_b_160k.pth'))\n",
    "cfg.MODEL.LAYERS = list(range(4))\n",
    "cfg.MODEL.LAYER_WIDTHS = [128, 256, 512, 1024]\n",
    "cfg.MODEL.BOTTLENECK_DIM = 128  # can be reduced to speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainnet.plmodel import PLModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "plmodel = PLModel(\n",
    "    cfg, \n",
    "    backbone, \n",
    "    draw=False,  # draw on each epoch end\n",
    "    cached=False,  # cache the features into cpu memory in first epoch\n",
    ")\n",
    "# plmodel.validation_epoch_end() is called on validation epoch to draw\n",
    "plmodel = plmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        # dirpath=checkpoints_path, # <--- specify this on the trainer itself for version control\n",
    "        filename=\"model_{epoch:02d}\",\n",
    "        every_n_epochs=1,\n",
    "        save_top_k=-1,  # <--- this is important!\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    gradient_clip_val=0.5,\n",
    "    precision=32,  # auto_fp16 already in dat code\n",
    "    limit_train_batches=1.0,\n",
    "    limit_val_batches=1.0,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "trainer.fit(plmodel)\n",
    "# 40 min on default colab"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
